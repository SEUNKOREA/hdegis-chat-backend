"""
ë¦¬íŒ©í† ë§ëœ RAG íŒŒì´í”„ë¼ì¸ ì‚¬ìš© ì˜ˆì‹œ - Config ì¤‘ì‹¬ ì„¤ê³„
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.abspath(__file__)) + "/..")

import warnings
from urllib3.exceptions import InsecureRequestWarning
from dotenv import load_dotenv

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore', category=InsecureRequestWarning)

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from app.factories import RAGPipelineFactory
from app.config.pipeline_config import PipelineConfig, SearchConfig, GenerationConfig, ContextConfig, StorageConfig, ElasticsearchConfig
from app.utils.formatters import format_search_results
import logging

# ë¡œê¹… ì„¤ì • - ìƒì„¸ ë¡œê·¸ëŠ” DEBUGë¡œ ì¡°ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì • í•¨ìˆ˜"""
    
    # ë£¨íŠ¸ ë¡œê±° ì„¤ì •
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        force=True
    )
    
    # ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ ë ˆë²¨ì„ WARNINGìœ¼ë¡œ ì„¤ì • (ë§¤ìš° ìƒì„¸í•œ ë¡œê·¸ ìˆ¨ê¹€)
    external_loggers = [
        'httpx',                    # HTTP ìš”ì²­ ë¡œê·¸ (POST, GET ë“±)
        'elastic_transport.transport',  # Elasticsearch ìš”ì²­ ë¡œê·¸ (ë§¤ POST ìš”ì²­)
        'google_genai.models',      # Google AI ëª¨ë¸ AFC ë¡œê·¸
        'urllib3.connectionpool',   # HTTP ì—°ê²° í’€ ë¡œê·¸
        'requests.packages.urllib3.connectionpool'
    ]
    
    for logger_name in external_loggers:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.WARNING)  # WARNING ì´ìƒë§Œ ì¶œë ¥
    
    # ì£¼ìš” ì‹¤í–‰ ë‹¨ê³„ëŠ” INFOë¡œ ìœ ì§€í•  ëª¨ë“ˆë“¤
    important_loggers = [
        'factories',                    # íŒ©í† ë¦¬ ìƒì„± ë¡œê·¸
        'pipeline.rag_pipeline',        # RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë‹¨ê³„
        'pipeline.retriever',           # ê²€ìƒ‰ ë‹¨ê³„
        'pipeline.context_builder',     # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ë‹¨ê³„
        'pipeline.generator',           # ë‹µë³€ ìƒì„± ë‹¨ê³„
        'utils.formatters',             # ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
        'core.search.elastic_searcher', # Elasticsearch ì—°ê²°/ê²°ê³¼ ìš”ì•½
        'core.embedding.google_embedder', # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        'core.generation.gemini_generator', # ìƒì„± ëª¨ë¸ ì´ˆê¸°í™”
    ]
    
    for logger_name in important_loggers:
        logger = logging.getLogger(logger_name)
        logger.setLevel(logging.INFO)  # INFO ë ˆë²¨ ìœ ì§€

# ë¡œê¹… ì„¤ì • ì ìš©
setup_logging()
logger = logging.getLogger(__name__)


def create_custom_config():
    """ëª¨ë“  ì„¤ì • ì˜µì…˜ì„ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•œ ì»¤ìŠ¤í…€ config ìƒì„±"""
    
    # ========== ê²€ìƒ‰ ì„¤ì • ==========
    search_config = SearchConfig(
        # í•µì‹¬ ê²€ìƒ‰ ì„¤ì •
        index_name="hdegis-text-multilingual-embedding-002",  # ê²€ìƒ‰ ì¸ë±ìŠ¤
        search_method="hybrid",                               # ê²€ìƒ‰ ë°©ë²• [keyword|vector|hybrid|hyde|hyde_hybrid]
        top_k=10,                                            # ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
        tolerance=3,                                         # í˜ì´ì§€ í™•ì¥ ë²”ìœ„ (0ì´ë©´ í™•ì¥ ì•ˆí•¨)
        
        # ê²€ìƒ‰ ìƒì„¸ ì„¤ì •
        vector_search_candidates=100,                        # ë²¡í„° ê²€ìƒ‰ í›„ë³´ ìˆ˜
        text_search_operator="or",                           # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì—°ì‚°ì [or|and]
        text_search_type="best_fields",                      # í…ìŠ¤íŠ¸ ê²€ìƒ‰ íƒ€ì…
        vector_weight=0.4,                                   # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ë²¡í„° ê°€ì¤‘ì¹˜
        text_weight=0.6,                                     # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ í…ìŠ¤íŠ¸ ê°€ì¤‘ì¹˜
    )
    
    # ========== ìƒì„± ì„¤ì • ==========
    generation_config = GenerationConfig(
        default_model="gemini-2.0-flash-001",
        
        # í‚¤ì›Œë“œ ìƒì„± ì„¤ì •
        keyword_generation={
            "model": "gemini-2.0-flash-001",
            "temperature": 0.1,
            "max_output_tokens": 256
        },
        
        # HyDE ë¬¸ì„œ ìƒì„± ì„¤ì •
        hyde_generation={
            "model": "gemini-2.0-flash-001",
            "temperature": 0.3,
            "max_output_tokens": 512
        },
        
        # ìµœì¢… ë‹µë³€ ìƒì„± ì„¤ì •
        answer_generation={
            "model": "gemini-2.0-flash-001",
            "temperature": 0.7,
            "max_output_tokens": 2048
        }
    )
    
    # ========== ìŠ¤í† ë¦¬ì§€ ì„¤ì • ==========
    storage_config = StorageConfig(
        storage_type="minio",                  # [minio|gcs]
        bucket_name="ksoe",
        local_temp_dir="tmp"
    )
    
    # ========== ì»¨í…ìŠ¤íŠ¸ ì„¤ì • ==========
    context_config = ContextConfig(
        context_type="text",                   # [text|image|both]
        text_field="extracted_text"            # [content|extracted_text]
    )
    
    # ========== Elasticsearch ì„¤ì • ==========
    elasticsearch_config = ElasticsearchConfig(
        verify_certs=False,
        request_timeout=30,
        max_retries=3,
        retry_on_timeout=True
    )
    
    # ========== ì „ì²´ ì„¤ì • ì¡°í•© ==========
    return PipelineConfig(
        search=search_config,
        generation=generation_config,
        storage=storage_config,
        context=context_config,
        elasticsearch=elasticsearch_config
    )


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ì»¤ìŠ¤í…€ ì„¤ì • ì‚¬ìš©"""
    
    logger.info("ğŸš€ ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì¤‘...")
    
    # ========== ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ìƒì„± ==========
    custom_config = create_custom_config()
    pipeline = RAGPipelineFactory.create_pipeline(config=custom_config)
    
    # íŒŒì´í”„ë¼ì¸ ì„¤ì • í™•ì¸
    logger.info(f"ğŸ“‹ í˜„ì¬ ì„¤ì •: {pipeline.get_config()}")
    
    # ========== í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì„¤ì • ==========
    user_query = "Are there any requirements regarding the operating method of the circuit breaker, such as spring-operated or hydraulic-operated?"
    user_filter = "3. Customer Standard Specifications/Spain/REE"
    
    # ========== íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ë™ì  ë°ì´í„°ë§Œ) ==========
    logger.info("ğŸ” ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
    
    # ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ê³¼ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•¨ê»˜ ë°›ê¸°
    answer_stream, total_hits, original_hits = pipeline.run_stream(user_query, user_filter)
    
    # ========== ê²°ê³¼ ì¶œë ¥ ==========
    print("\n" + "="*50 + " USER " + "="*50)
    print(f"Query: {user_query}")
    print(f"Filter: {user_filter}")
    
    print("\n" + "="*45 + " AI ASSISTANT " + "="*45)
    print("Answer:\n")
    
    # ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ì¶œë ¥
    for chunk in answer_stream:
        print(chunk, end="", flush=True)
    
    print("\n\n")  # ë‹µë³€ ì™„ë£Œ í›„ ì¤„ë°”ê¿ˆ
    
    print("\n" + "="*45 + " REFERENCE " + "="*46)
    print(f"Original hits: {len(original_hits)}")
    print(f"Total hits (with expansion): {len(total_hits)}")
    print(format_search_results(original_hits))
    
    print("\n" + "="*100)


if __name__ == "__main__":
    try:
        # ğŸš€ ë©”ì¸ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¬ë°)
        main()
        
        logger.info("âœ… ì‹¤í–‰ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise